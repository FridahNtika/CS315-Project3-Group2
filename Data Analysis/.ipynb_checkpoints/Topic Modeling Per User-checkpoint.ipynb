{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81d4f25a-dc3c-48f4-bcf2-f2ef01f2f71c",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4290e5-2c70-4c24-a7ae-79493493d0e7",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1f9e9c-06bf-4fac-a6a3-4201348251bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install clean-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8010bb9c-afa6-41fa-911e-8f9cf60d8fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, types\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bba74240-37d1-44c2-a3b9-b57f78c19d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from cleantext import clean\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dacbf9-39c3-4f82-8dd2-562524dc4d97",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11d82d84-1a68-4cde-855d-6e956a292e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonToDF(name):\n",
    "    \"\"\"Read a list of sentences from the JSON file, store them in a dataframe\"\"\"\n",
    "    \n",
    "    with open(f\"{name}.json\") as fin:\n",
    "        textList = json.load(fin)\n",
    "\n",
    "    # create a name for each document, based on its category\n",
    "    indexNames = [f\"{name}\" for i in range(len(textList))]\n",
    "\n",
    "    # create the dataframe, it will have one column and one index\n",
    "    df = pd.DataFrame(data=textList, index=indexNames)\n",
    "    df.columns = ['document']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efbe9bea-8a34-4115-8c93-930884107f52",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'user1.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m user1 \u001b[38;5;241m=\u001b[39m jsonToDF(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m user2 \u001b[38;5;241m=\u001b[39m jsonToDF(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m user3 \u001b[38;5;241m=\u001b[39m jsonToDF(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36mjsonToDF\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjsonToDF\u001b[39m(name):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read a list of sentences from the JSON file, store them in a dataframe\"\"\"\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[1;32m      5\u001b[0m         textList \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(fin)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# create a name for each document, based on its category\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'user1.json'"
     ]
    }
   ],
   "source": [
    "user1 = jsonToDF(\"user1\")\n",
    "user2 = jsonToDF(\"user2\")\n",
    "user3 = jsonToDF(\"user3\")\n",
    "user4 = jsonToDF(\"user4\")\n",
    "user5 = jsonToDF(\"user5\")\n",
    "user6 = jsonToDF(\"user6\")\n",
    "user7 = jsonToDF(\"user7\")\n",
    "user8 = jsonToDF(\"user8\")\n",
    "user9 = jsonToDF(\"user9\")\n",
    "user10 = jsonToDF(\"user10\")\n",
    "user7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e34969-77e7-4353-9036-2b167173cfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanDf(df):\n",
    "    df.dropna(subset=['document'])\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dfb4c5-5e7a-47f8-8559-1d9ab73981cf",
   "metadata": {},
   "source": [
    "Concatenate all of them in a single dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d983e153-7df3-4c9c-b27d-778e1f4d1adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDocs = [user1, user2, user3, user4, user5, user6, user7, user8, user9, user10]\n",
    "for df in allDocs:\n",
    "    df = cleanDf(df)\n",
    "user7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7cf617-1a20-4dce-ab4b-b148d827a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates\n",
    "allDocs.drop_duplicates(inplace=True)\n",
    "allDocs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263645f5-1746-41d8-a0cb-152396c2954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\",1000)\n",
    "#allDocs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf0a59-2006-4364-9fa9-7ed86ac8de90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHashtags(text):\n",
    "  \"\"\"Takes a string phrase and returns hashtags if present\"\"\"\n",
    "  if isinstance(text, str):\n",
    "    return re.findall(r\"#(\\S+)\", text.lower())\n",
    "  return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9ffc65-ab48-4c5d-99f1-5ccee42876e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracts the hashtags for each post\n",
    "allDocs['hashtags'] = allDocs['document'].apply(getHashtags)\n",
    "allDocs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956f8fba-a74a-4737-9a28-24dba8c1c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitHashtags(sentence):\n",
    "    \"\"\"Takes a sentence and splits hashtags if present\"\"\"\n",
    "    if isinstance(sentence, str):\n",
    "        hashtags = [tag.strip('#') for tag in sentence.split('#') if tag.strip('#')]\n",
    "        return hashtags\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594ccedc-85ba-4ae1-b426-7cb4c9ab03ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_EMOJI = re.compile('[\\U00010000-\\U0010ffff]', flags=re.UNICODE)\n",
    "\n",
    "def strip_emoji(text):\n",
    "    return RE_EMOJI.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93dfabb-a485-4d42-908c-e1b29773df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "toRemove = ['fyp', '#trending', 'trending', '#foryou', 'foryou', '#viral', 'viral', 'foryoupage', 'fy', 'fypage', 'tiktok', 'video', 'forypu', 'fup', 'everyonefyp', 'reaction', 'fypviral']\n",
    "\n",
    "def remove_words(sentence):\n",
    "    #if isinstance(sentence, str):\n",
    "        sent = strip_emoji(sentence)\n",
    "        hashtags = splitHashtags(sent)\n",
    "        final = []\n",
    "        for hash in hashtags:\n",
    "            #print(type(hash))\n",
    "            if hash.lower() not in toRemove and hash not in final:\n",
    "                final.append(hash)\n",
    "        return ' '.join(final)\n",
    "\n",
    "allDocs['document'] = allDocs['document'].apply(remove_words)\n",
    "pd.set_option(\"display.max_colwidth\",1000)\n",
    "allDocs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e40090-a6a5-4781-a0fd-4d2a959d1bd4",
   "metadata": {},
   "source": [
    "Jaccard index on suggested words and video descriptons between users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ca96ef-0792-4e69-965d-eae6e3332ea9",
   "metadata": {},
   "source": [
    "### Convert to document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11deb981-8c74-47c2-855f-4ab27b7948c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86434a36-e195-442c-81a1-40da2a903844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the vectorizer\n",
    "vectorizer = CountVectorizer(\n",
    "    strip_accents='unicode',\n",
    "    stop_words='english',\n",
    "    lowercase=True,\n",
    "    token_pattern=r'\\b[a-zA-Z]{3,}\\b', # we want only words that contain letters and are 3 or more characters long\n",
    ")\n",
    "\n",
    "# Transform our data into the document-term matrix\n",
    "dtm = vectorizer.fit_transform(allDocs['document'])\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f9f1b-3507-47e8-978b-a2035a306134",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc25ef0-2211-4477-a4bf-d6007c7cd39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix2Doc(dtMatrix, features, index):\n",
    "    \"\"\"Turns each row of the document-term matrix into a list of terms\"\"\"\n",
    "    row = dtMatrix.getrow(index).toarray()\n",
    "    non_zero_indices = row.nonzero()[1]\n",
    "    words = [features[idx] for idx in non_zero_indices]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808f7633-97f7-4fe3-9f8b-5060af6bbc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDocsAsTerms = [matrix2Doc(dtm, feature_names, i) for i in range(dtm.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8455a30-6070-49be-bc71-3c20f4960a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDocs['terms'] = allDocsAsTerms\n",
    "pd.set_option(\"display.max_colwidth\",1000)\n",
    "allDocs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce92542-061a-4259-8aea-2f22db03fc07",
   "metadata": {},
   "source": [
    "### Fitting the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3220c919-1ac2-4b1f-8c4b-24d1186219db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8491ff-877b-4f47-87f7-50dd199562e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# We are going to test multiple values for the number of topics\n",
    "search_params = {'n_components': [5, 10, 15, 20, 25, 30, 35]}\n",
    "\n",
    "# Initialize the LDA model\n",
    "#lda = LatentDirichletAllocation()\n",
    "\n",
    "# Initialize a Grid Search with cross-validation instance\n",
    "#grid = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "# Do the Grid Search\n",
    "#grid.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c04521d-9580-4d9a-a2a5-5bb88f7652f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9ac34-52b9-44d0-ba8e-4808784f595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model\n",
    "#best_lda_model = grid.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "#print(\"Best Model's Params: \", grid.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "#print(\"Best Log Likelihood Score: \", grid.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "#print(\"Model Perplexity: \", best_lda_model.perplexity(dtm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6449bd7-dc86-4704-9262-78bdfc1b1d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Initialize the model\n",
    "lda = LatentDirichletAllocation(n_components=5, # we are picking the number of topics arbitrarely at the moment\n",
    "                                random_state=0)\n",
    "# Step 2: Fit the model\n",
    "lda.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e9a68-87cd-4bfa-b92d-9c43c5e50794",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b886d-ca5f-4419-accd-b01b68b0eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_dist = lda.transform(dtm)\n",
    "doc_topic_dist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7570f070-9935-4764-b31d-37a25dc82068",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8176acd1-8a4a-4308-9f47-651d11c3936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, features, no_top_words):\n",
    "    \"\"\"Helper function to show the top words of a model\"\"\"\n",
    "    for topic_idx, topic in enumerate(model.components_):                                                                                                             \n",
    "        print(f\"Topic {topic_idx}:\")\n",
    "        print(\" \".join([features[i]\n",
    "                        for i in topic.argsort()[:-no_top_words-1:-1]])) # syntax for reversing a list [::-1]\n",
    "\n",
    "display_topics(lda, feature_names, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831802c6-e4a4-4389-a08d-78d6d4c63267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayHeader(model, features, no_top_words):\n",
    "    \"\"\"Helper function to show the top words of a model\"\"\"\n",
    "    topicNames = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topicNames.append(f\"Topic {topic_idx}: \" + (\", \".join([features[i]\n",
    "                             for i in topic.argsort()[:-no_top_words-1:-1]])))\n",
    "    return topicNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada1ce06-37ce-4d6f-802c-f9bbea664650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names\n",
    "topicnames = displayHeader(lda, feature_names, 0)\n",
    "\n",
    "# index names\n",
    "docnames = allDocs.index.tolist() # We will use the original names of the documents\n",
    "\n",
    "# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(doc_topic_dist, 3), \n",
    "                                 columns=topicnames, \n",
    "                                 index=docnames)\n",
    "\n",
    "# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1) # finds the maximum argument\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "\n",
    "df_document_topic.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8643811-c8c9-4f15-916d-07faa4fdcfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_document_topic = df_document_topic.reset_index()\n",
    "#df_document_topic = df_document_topic.drop(columns = ['dominant_topic'])\n",
    "df_document_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b846cb8d-eb80-4cfb-a771-cfb1dc9f2411",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_document_topic.groupby('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05b2b17-d973-4f73-83e6-0bd06db3a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = grouped.mean()\n",
    "averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bc7cd5-bc43-43e4-bf96-ccb47ae8269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(averages, cmap=\"YlGnBu\", fmt=\"d\")\n",
    "plt.title('Heatmap of User-Topic Probabilities')\n",
    "plt.xlabel('Topics')\n",
    "plt.ylabel('Users')\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d74b003-77e5-4831-8212-6b1fe806c24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_distribution = df_document_topic['dominant_topic'].value_counts().reset_index(name=\"Num Documents\")\n",
    "df_topic_distribution.columns = ['Topic Num', 'Num Video Descriptions']\n",
    "df_topic_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae20d8-48b6-49fe-98e2-7d463ee2c9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from DataFrame columns\n",
    "x_values = df_topic_distribution['Topic Num']\n",
    "y_values = df_topic_distribution['Num Video Descriptions']\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.bar(x_values, y_values)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Topics')\n",
    "plt.ylabel('Video Counts')\n",
    "plt.title('Bar Chart of Topics vs. Videos')\n",
    "\n",
    "# Rotate x-axis labels for better readability (if needed)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b68c84c-2971-4f12-a2b8-6a20d4fdc390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "df_document_topic.reset_index(inplace=True)\n",
    "df_document_topic.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7d92b7-352f-4f62-a4cc-2335029038e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from DataFrame columns\n",
    "x_values = df_document_topic['index']\n",
    "y_values = df_document_topic['dominant_topic']\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.bar(x_values, y_values)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Topics')\n",
    "plt.ylabel('Video Counts')\n",
    "plt.title('Bar Chart of Topics vs. Videos')\n",
    "\n",
    "# Rotate x-axis labels for better readability (if needed)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8477dc02-fc80-4001-ba2a-c45ab74daefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most frequent dominant_topic per user\n",
    "most_frequent_topics = df_document_topic.groupby('index')['dominant_topic'].apply(lambda x: x.mode().iloc[0])\n",
    "\n",
    "# Print the result\n",
    "type(most_frequent_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f87dfb6-15d6-429b-af8c-51dcf6da2030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most frequent dominant_topic per user\n",
    "most_frequent_topics = df_document_topic.groupby('index')['dominant_topic'].apply(lambda x: x.value_counts().idxmax())\n",
    "\n",
    "# Print the result\n",
    "most_frequent_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2851c2-fa29-4a38-818b-4e8d31f18d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "most_frequent_topics.value_counts().plot(kind='bar')\n",
    "plt.title('Most Frequent Dominant Topic per User')\n",
    "plt.xlabel('Dominant Topic')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
