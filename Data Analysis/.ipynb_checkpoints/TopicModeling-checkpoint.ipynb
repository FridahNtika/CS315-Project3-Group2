{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81d4f25a-dc3c-48f4-bcf2-f2ef01f2f71c",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8010bb9c-afa6-41fa-911e-8f9cf60d8fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, types\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba74240-37d1-44c2-a3b9-b57f78c19d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4752d9-a721-46e6-a5e6-c5648129113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = \"/Users/fridahntika/Documents/CS315/Project 3/CS315-Project3-Group2/Data Analysis/user1.csv\"\n",
    "d2 = \"/Users/fridahntika/Documents/CS315/Project 3/CS315-Project3-Group2/Data Analysis/user2.csv\"\n",
    "d3 = \"/Users/fridahntika/Documents/CS315/Project 3/CS315-Project3-Group2/Data Analysis/user3.csv\"\n",
    "d4 = \"/Users/fridahntika/Documents/CS315/Project 3/CS315-Project3-Group2/Data Analysis/user4.csv\"\n",
    "d5 = \"/Users/fridahntika/Documents/CS315/Project 3/CS315-Project3-Group2/Data Analysis/user5.csv\"\n",
    "#d6\n",
    "#d7\n",
    "#d8\n",
    "#d9\n",
    "#d10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78526228-16b4-46d2-aa26-463bf32afd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(d1)\n",
    "df1['User'] = 'User1'\n",
    "df2 = pd.read_csv(d2)\n",
    "df2['User'] = 'User2'\n",
    "df3 = pd.read_csv(d3)\n",
    "df3['User'] = 'User3'\n",
    "df4 = pd.read_csv(d4)\n",
    "df4['User'] = 'User4'\n",
    "df5 = pd.read_csv(d5)\n",
    "df5['User'] = 'User5'\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61c1f56-ddc7-48e2-b048-cb6296ccc3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"d2:\", df2.shape)\n",
    "#print(\"d3:\", df3.shape)\n",
    "#print(\"d4:\", df4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dfb4c5-5e7a-47f8-8559-1d9ab73981cf",
   "metadata": {},
   "source": [
    "Concatenate all of them in a single dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d983e153-7df3-4c9c-b27d-778e1f4d1adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDocs = pd.concat([df1, df2, df3, df4, df5])\n",
    "allDocs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c9566d-7852-425e-bd56-41ee53002724",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDocs.set_index('User', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263645f5-1746-41d8-a0cb-152396c2954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da027b-84a8-4c26-a829-adf68d07a0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHashtags(text):\n",
    "  \"\"\"Takes a string phrase and returns hashtags if present\"\"\"\n",
    "  if isinstance(text, str):\n",
    "    return re.findall(r\"#(\\S+)\", text.lower())\n",
    "  return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987d1aca-1868-4412-9868-39d78456efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "toRemove = ['fyp', 'trending', 'foryou', 'viral', 'foryoupage', 'fy', 'fypage', 'tiktok', 'video', 'forypu', 'fup', 'everyonefyp', 'reaction', 'fypviral']\n",
    "\n",
    "def remove_words(sentence):\n",
    "    #hashtags = getHashtags(sentence)\n",
    "    #if\n",
    "    words = sentence.split()\n",
    "    final = [word for word in words if word.lower() not in toRemove]\n",
    "    #toRemove.append(hashtags)\n",
    "    return ' '.join(final)\n",
    "\n",
    "allDocs['Vide descriptions'] = allDocs['Vide descriptions'].apply(remove_words)\n",
    "allDocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11deb981-8c74-47c2-855f-4ab27b7948c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86434a36-e195-442c-81a1-40da2a903844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the vectorizer\n",
    "vectorizer = CountVectorizer(\n",
    "    strip_accents='unicode',\n",
    "    stop_words='english',\n",
    "    lowercase=True,\n",
    "    token_pattern=r'\\b[a-zA-Z]{3,}\\b', # we want only words that contain letters and are 3 or more characters long\n",
    ")\n",
    "\n",
    "# Transform our data into the document-term matrix\n",
    "dtm = vectorizer.fit_transform(allDocs['Vide descriptions'])\n",
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce92542-061a-4259-8aea-2f22db03fc07",
   "metadata": {},
   "source": [
    "### Fitting the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3220c919-1ac2-4b1f-8c4b-24d1186219db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6449bd7-dc86-4704-9262-78bdfc1b1d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Initialize the model\n",
    "lda = LatentDirichletAllocation(n_components=5, # we are picking the number of topics arbitrarely at the moment\n",
    "                                random_state=0)\n",
    "# Step 2: Fit the model\n",
    "lda.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b489657-07a5-44a8-bd37-cbd5cf07d3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e9a68-87cd-4bfa-b92d-9c43c5e50794",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b886d-ca5f-4419-accd-b01b68b0eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_dist = lda.transform(dtm)\n",
    "doc_topic_dist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7570f070-9935-4764-b31d-37a25dc82068",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8176acd1-8a4a-4308-9f47-651d11c3936a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_topics(model, features, no_top_words):\n",
    "    \"\"\"Helper function to show the top words of a model\"\"\"\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {topic_idx}:\")\n",
    "        print(\" \".join([features[i]\n",
    "                        for i in topic.argsort()[:-no_top_words-1:-1]])) # syntax for reversing a list [::-1]\n",
    "\n",
    "display_topics(lda, feature_names, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831802c6-e4a4-4389-a08d-78d6d4c63267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayHeader(model, features, no_top_words):\n",
    "    \"\"\"Helper function to show the top words of a model\"\"\"\n",
    "    topicNames = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topicNames.append(f\"Topic {topic_idx}: \" + (\", \".join([features[i]\n",
    "                             for i in topic.argsort()[:-no_top_words-1:-1]])))\n",
    "    return topicNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada1ce06-37ce-4d6f-802c-f9bbea664650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names\n",
    "topicnames = displayHeader(lda, feature_names, 5)\n",
    "\n",
    "# index names\n",
    "docnames = allDocs.index.tolist() # We will use the original names of the documents\n",
    "\n",
    "# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(doc_topic_dist, 3), \n",
    "                                 columns=topicnames, \n",
    "                                 index=docnames)\n",
    "\n",
    "# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1) # finds the maximum argument\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "\n",
    "df_document_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d74b003-77e5-4831-8212-6b1fe806c24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_distribution = df_document_topic['dominant_topic'].value_counts().reset_index(name=\"Num Documents\")\n",
    "df_topic_distribution.columns = ['Topic Num', 'Num Sentences']\n",
    "df_topic_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cebfee-ff7e-4be9-ac34-5126ece8d3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afdd0ef-ad00-40b4-863d-817669cdb79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to test multiple values for the number of topics\n",
    "search_params = {'n_components': [5, 10, 15, 20, 25, 30, 35]}\n",
    "\n",
    "# Initialize the LDA model\n",
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "# Initialize a Grid Search with cross-validation instance\n",
    "grid = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "# Do the Grid Search\n",
    "grid.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8494c1c-fc66-4748-9885-30bddee6e492",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd966f8e-088a-43e6-85a4-ce926eb44541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model\n",
    "best_lda_model = grid.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", grid.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", grid.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(dtm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c0fe90-867e-448a-9a06-93aadf8d1c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {'n_components': [1,2,3,4,5,6]}\n",
    "\n",
    "lda = LatentDirichletAllocation()\n",
    "grid = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "grid.fit(dtm)\n",
    "\n",
    "# Best Model\n",
    "best_lda_model = grid.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", grid.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", grid.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(dtm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2576467e-f1ff-48cc-af0f-bf5f8ae28097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
